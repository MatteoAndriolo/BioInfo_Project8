# Project 8 -- BioInformatics

ASSIGNED to G. Pisacreta, A.  Matteo
# Metagenomics classification: long reads vs short reads 
One of the most important problem in metagenomic is the analysis of a sample in order to detect all the species (human, bacteria, virus etc) that are contained in the sample.

Several tools exist for the classification of metagenomic reads extracted from the sample and [Kraken2](https://ccb.jhu.edu/software/kraken2/) is one of the best performing (already installed in the BCB server).

However the __classification accuracy may vary and it can depend on the length of reads__.

The idea of the project is to compare the performance of Kraken2 when used with reads of different technologies.


[mason2](https://github.com/seqan/seqan/tree/master/apps/mason2):
    Short reads simulator

[SimLoRD](https://bitbucket.org/genomeinformatics/simlord/src/master/):
    Long reads Simulator


# Structure directory
* docs
    * contains general, usefull informations
* src
    * contains all the script and code used
* reads
    * contains all the simulated reads
        * .\reads\reads_50\
* ref
    * contains the reference genomes used for the simulation
        * .\ref\ref_50\
* fasta
    * contains the fasta files generated by the simulations
        * .\fasta\fasta_50\
* *enviroment.yml* 
    * list of necessary packages. Useful to reconstruct enviroment using ***conda***.
    * tested only on linux

Both in ***ref*** and in ***reads*** are present files *metadata.json* that contains information about data generated.

# Scripts
## config.py
Contains many of the parameters required by the others script
Manages the folders organizations
## 00_ref_metadata.py
Generate all the ref's "metadata.json" files used by other scripts
## 01_sim_reads.py
Generate all the reads
## 02_construct_fasta.py
Starting from the reads generate ".fasta" files 
```text
>S0R[number_read] name
read
```
# SETUP
## SIMLORD
* coverage = 20x, automatically calculates number of reads to perform 
* probability insertions = 0.11
* probability deletions = 0.40
* probability substitution = 0.01
## COVERAGE
* coverage = 20x, number of reads calculated using (rough formula) for coverage $coverage=(reads_lenght*number_reads)/genome_size$
* probability errors = have been used the default ones
## Enterz
[ncbi doc](https://www.ncbi.nlm.nih.gov/books/NBK179288/)
Utility used for query automation on ncbi databases.

There were some problems with taxid of reference file. Using this tool has been possible to fetch taxids for each contig and that has been used as true value. (! only in Saccharomyces cerevisiae there is sequence _NC_001136.1_ that has got taxid (_4932_) different from the other 16 (_559292_))

